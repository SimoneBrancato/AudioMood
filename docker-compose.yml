version: '2'
services:

  kafka:
    image: bitnami/kafka:3.7.0
    container_name: kafka
    ports:
      - 9092:9092
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:2181
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_KRAFT_CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
      - KAFKA_DELETE_TOPIC_ENABLE=true
    volumes:
      - ./kafka:/bitnami/kafka
    entrypoint: /bin/bash
    command: -c "rm -rf /bitnami/kafka/data/* && /opt/bitnami/scripts/kafka/entrypoint.sh /opt/bitnami/scripts/kafka/run.sh"

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    ports:
      - 8080:8080
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: PLAINTEXT://kafka:9092

  spark-sentiment:
    build:
      context: spark/sparknlp
      dockerfile: ./Dockerfile
    container_name: spark-sentiment 
    volumes:
      - ./spark/sparknlp/code/:/code
    command: > 
      /opt/spark/bin/spark-submit --driver-memory 3g --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" --conf spark.jsl.settings.pretrained.cache_folder="/tmp" --packages com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.elasticsearch:elasticsearch-spark-30_2.12:8.13.4  /code/sentiment_analysis_sparknlp.py
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      producer:
        condition: service_started

  spark-entities:
    build:
      context: spark/sparknlp
      dockerfile: ./Dockerfile
    container_name: spark-entities
    volumes:
      - ./spark/sparknlp/code/:/code
    command: > 
      /opt/spark/bin/spark-submit --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" --conf spark.jsl.settings.pretrained.cache_folder="/tmp" --packages com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.elasticsearch:elasticsearch-spark-30_2.12:8.13.4  /code/entities_recognition_sparknlp.py
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      producer:
        condition: service_started

  spark-summarization:
    build:
      context: spark/openai
      dockerfile: ./Dockerfile
    container_name: spark-summary
    volumes:
      - ./spark/openai/code/:/code
    env_file:
    - ./.env
    command: > 
      /opt/spark/bin/spark-submit --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" --conf spark.jsl.settings.pretrained.cache_folder="/tmp" --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.elasticsearch:elasticsearch-spark-30_2.12:8.13.4  /code/summarization_openai.py
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      producer:
        condition: service_started

  elasticsearch:                                           
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: elasticsearch                   
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - http.port=9200
      - ES_JAVA_OPTS=-Xms2g -Xmx2g
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.7.1
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    volumes:
      - ./kibana/config:/usr/share/kibana/config
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
  
  init-kibana:
    image: curlimages/curl:8.8.0
    container_name: init-kibana
    volumes:
      - ./kibana/data/export.ndjson:/export.ndjson
      - ./kibana/load-dashboard.sh:/usr/share/kibana/load-dashboard.sh
    command: ["/bin/sh", "/usr/share/kibana/load-dashboard.sh"]
    depends_on:
      - kibana
      - flask
      
  init-kafka:
    image: bitnami/kafka:3.7.0
    container_name: init-kafka
    depends_on:
      kafka:
        condition: service_started
      kafka-ui:
        condition: service_started
      elasticsearch:
        condition: service_started
    entrypoint: ['/bin/sh', '-c']
    command: |
      "
      echo 'Creating Kafka topic.'
      kafka-topics.sh --create --topic sentiment --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 --if-not-exists
      kafka-topics.sh --create --topic entities --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 --if-not-exists
      kafka-topics.sh --create --topic summary --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 --if-not-exists

      echo 'Successfully updated topic list:'
      kafka-topics.sh --list --bootstrap-server kafka:9092
      "

  logstash:
    build: 
      context: logstash/
      dockerfile: ./Dockerfile
    container_name: logstash
    environment:
      XPACK_MONITORING_ENABLED: "false"
      pipeline.ecs_compatibility: disabled
    ports:
      - 9700:9700
    expose:
      - 9700
    depends_on:
      - kafka
      - kafka-ui
      - elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:9700 || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 10

  producer:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: audiomood_producer
    container_name: producer
    ports:
      - "5001:5001"
    depends_on:
      logstash:
        condition: service_healthy

  flask:
    container_name: flask
    build:
      context: app/
      dockerfile: ./Dockerfile
    image: flask
    ports:
      - "5000:5000"
    depends_on:
      producer:
        condition: service_started